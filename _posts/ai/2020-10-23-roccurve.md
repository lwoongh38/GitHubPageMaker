---
layout: post
current: post
cover:  assets/built/images/roc.jpg
navigation: True
title: ROC curve에 대해 알아보자
date: 2020-10-23 19:00:00
tags: [ai]
class: post-template
subclass: 'post tag-ai'
author: woongE
---
#평가지표 #ROCcurve


{% include ai-table-of-contents.html %}

# ROC curve에 대해 알아보자

선형회귀? 그게 뭐야? 회귀라는 말을 연어를 통해서만 들어본 그대.
말이 어렵지 사실 그 개념 자체는 이미 우리가 알고있는 것이나 마찬가지다. 최대한 쉽게쉽게 풀어서 설명해볼 터이니
오늘도 시작해보자.

선형회귀라고 대놓고 주제를 던졌으니 의미를 먼저 알아야겠지?
y = ax+b 라는 식이 있다면 입력항인 x와 출력항인 y의 선형 상관관계를 모델링하는 기법이다. 
아직도 모호한가? 그러면 이 말을우리 생활 속의 예제로 녹여보자.

![image](https://user-images.githubusercontent.com/70134676/96222124-a1f41000-0fc6-11eb-8d00-94644528b877.png)


저 위의 `y = ax+b`를 시험점수에 대한 식이라고 예를 들면,
- y = 물가
- x = 휴지가격
- a = 가중치(운송비용 등)
- b = 기본물가

이렇게 정리할 수 있다.
위의 그림대로라면 휴지가격을 알 때 물가가 어떠한지를 얻을 수 있다.
이것도 간단한 회귀식이다. 이처럼 수식화하지 않았을 뿐 우리 생활에는 다양한 회귀식들이 숨어있다.
그럼 여태까지 회귀식을 모르고도 사는데 전혀 문제가 없었는데 갑자기 왜 들고나와서 머리아프게 하는지 궁금해 하는 사람이 있을 것이다.
문제는 이처럼 간단한 회귀식이라면 상관이 없겠지만 데이터의 수가 엄청나게 많아지고 특징들이 많아진다면 사람의 머리로는 저런 생각을 하는 것이 불가능 할 것이다. 이를 위해 우리는 계산기(컴퓨터)의 힘을 빌리게 되고 컴퓨터의 좋은 성능을 이용하면 알고있었던 데이터(빨간 점)에서 답을 찾는 것 뿐만이 아닌, 새로운 데이터(x축, 휴지가격)을 바탕으로 정답(y축, 물가)를 예측해볼 수도 있다.
이것이 요즘 흔히 하는 말로 **머신러닝**이라고 하는 개념이다.
물론 머신러닝도 지도, 비지도 등 여러가지 갈래로 나뉘어지지만 위에서 설명한 머신러닝은 선형적인 관계를 가진 데이터를 위한 선형회귀 예측모델이 되는 것이다. 빨간점을 활용하여 학습시키면 다른 데이터(이지만 비슷한 선형관계를 가진) 파란점의 휴지가격을 알 때, 물가를 예측해볼 수 있는 것이다. 
한마디로 **선형회귀는 선형관계를 가진 데이터를 모델링하여 예측하기 위한 머신러닝의 일종**이다.

선형회귀 기법을 사용하여 데이터에 맞는 예측모델을 만들기 위해서는 회귀직선 필요하다.
![image](https://user-images.githubusercontent.com/70134676/96222090-97397b00-0fc6-11eb-8bdf-47ef8c0e2a32.png)

회귀직선이 말하고자 하는 바는 예측을 할 때 이러한 느낌으로 예측을하면 맞출 수 있을것이라는 일종의 경향성을 의미하고 위의 그림에서는 녹색선이 그 경향을 의미한다.  우리는 데이터로 빨간 점을 가지고 있고 이 데이터가 어떤 경향을 띄는지를 가장 잘 설명해주는 선이 바로 녹색 선이다. 

![image](https://user-images.githubusercontent.com/70134676/96223864-9524eb80-0fc9-11eb-8a0c-ffbd1840ad96.png)
이 선을 설명하기 위해서는 예측값과 잔차라는 개념을 알아야 하는데 예측값은 저 녹색선이 추정하는 값이고, 잔차는 관측값(빨간점의 물가)와 예측값(파란점의 물가)의 차이를 말한다.
녹색선은 그림의 검은점선으로 표시된 저 관측값과 파란점선의 예측값의 제곱의 합이 최소가 되어야 가장 경향을 잘 설명할 수 있다.
여기서 파란점선의 크기와 검은 점선 크기의 제곱의 합을 잔차제곱합이라고 하는데 이 잔차제곱합을 비용함수(cost function)라고 하는데 머신러닝 모델을 만드는 과정에서 비용함수를 최소화 하는 모델(선)을 찾는 과정을 학습이라고 한다.

저 녹색 선을 그려서 저 녹색선을 바탕으로 값을 예측하게 하는 과정 전반이 머신러닝 선형회귀 모델링이 되는 것이다.

선형회귀 모델은 주어져있지 않은 함수값을 보간하여 예측하는데 유용한데 예를들어 빨간점이 아닌, 없는 데이터 즉 파란점에 해당하는 휴지가격을 알고 있을 때 원래 데이터(빨간점)에는 없지만 녹색선을 이용하여 파란점의 휴지가격을 알 때  물가를 어림잡아 예측해볼 수 있는 것이다.

오늘은 머신러닝의 많은 모델 중 하나인 선형회귀에 대해서 알아보았다. 이제는 선형회귀에 대한 말이 나오면 자신있게 대화에 끼어들어보자.
앞으로도 다양한 머신러닝의 모델들을 알기쉽게 소개해보리라고 다짐하며 글을 마친다.



머신러닝에 대해 일주일간 다양한 모델들을 공부했다.
사용 목적에 따라 많은 종류의 머신러닝 모델이 존재하지만 결국 큰 맥락에서 보자면 
머신러닝은 결국 가지고 있는 데이터로 학습을 시키고, 학습시킨 모델을 이용하여 문제를 풀어내려고(예측하려고) 하는 것이다.
결국 모델의 성능을 높인다는 의미는 모델이 예측을 잘 할 수 있게 한다는 뜻이고 이를 위해서는 해당 모델을 정확하게 평가할 수 있어야 한다.

머신러닝 모델에 대해 공부하다보면 해당 모델이 어떤 매커니즘으로 작동하는지, 배경은 무엇인지 등을 배우게 되지만
공통적으로 모델마다 등장하는 섹터가 있다. 그것은 바로.....**평가지표**다.
위에서 말했듯이 제대로 모델의 성능을 알 수 있어야 개선이 가능하기 때문에 
모델을 제대로 평가하는 것도 만드는 것만큼이나 중요하다.
그래서 이번에는 공부했던 다양한 지표중에 이해가 제일 안갔던 `ROC curve`에 대해 알아보려고 한다.
함께 공부를 시작해보자.

ROC curve는 이진분류를 하는 모델의 성능을 평가하는 지표로 사용된다.
이진분류는 쉽게 말하면 O,X 문제처럼 두가지 중 하나를 고르는 분류를 말한다.
백문이 불여일견이라고 일단 그림을 보자.

![image](https://user-images.githubusercontent.com/70134676/96972847-04628880-1552-11eb-8a8c-a864568d2612.png)
출처 : http://www.navan.name/roc/

구 개의 큰 산 모양을 보이는 그림은 데이터에서 두 클래스의 분포를 나타낸다. (O,X 문제에서 O와 X의 분포)
암환자를 진단하는 모델을 만든다고 할 때, 오른쪽은 암환자, 왼쪽은 암환자가 아닌 경우이다.
산이 겹치는 부분 가운데의 threshold는 모델을 만든사람이 정하는 변수로 이 임계값을 기준으로 모델은 오른쪽에 있으면 암환자로, 왼쪽에 있으면 암환자가 아니라고 판단을 내리게 된다. 
그림의 좌 상단에 위치한 곡선이 ROC curve로 ROC curve는 위의 임계값에 대한 모델의 성능을 표시한 곡선이다. **핵심을 먼저 얘기하고 넘어가자면 저 커브 아래의 면적(AUC, Area Under the Curve)이 클수록 모델의 성능이 뛰어나다는 것을 의미**한다.

커브에 대해 살펴보려면 우선 축이 무엇인지 알아보자.
x축은 FPR y축은 TPR이라고 적혀있는데 이는 각각 

FPR은 False Positive rate
TPR은 True Positive rate

을 뜻한다.
![image](https://user-images.githubusercontent.com/70134676/96987496-0df1ed80-155e-11eb-9a44-81044441a48a.png)

의미는 같아도 해석을 사람마다 다르게하는 경향이 있으니 위 그림의 구성요소인 actual class와 predicted class에 대한 설명을 하고 넘어가면 좋을 것 같다.

먼저 actual class에는 True와 False로 나뉘는데 이는 예측결과가 맞으면 True, 틀리면 False라는 것을 의미한다.
다음 predicted class는 Positive와 Negative로 나뉘는데 이는 예측을 긍정적으로 했으면 Positive, 그렇지 않다면 Negative로 표현한다.

위로 돌아가서 암환자를 예로 들어보면 TPR은 실제로 암에 걸린사람을 암에 걸렸다고 예측했다는 것이고
FPR은 암환자라고 예측했으나 예측결과가 틀린것을 의미한다.

![image](https://user-images.githubusercontent.com/70134676/96972847-04628880-1552-11eb-8a8c-a864568d2612.png)

TPR이 높다는 의미는 실제로 암이 걸린 환자를 암이 걸렸다고 판단을 잘 내린다는 뜻이고
FPR이 높다는 의미는 암이 걸리지 않은 환자도 모두 암으로 판정한다는 의미이다. 
암환자를 적게 놓치고 싶다면 임계값을 왼쪽으로 옮겨(낮춰) 빨간 클래스가 임계값 오른쪽에 모두 들어가게 하면 암환자를 무조건 맞출 수 있게 되겠지만 반대로 암환자가 아닌사람을 암환자로 오진하는 경우도 그만큼 늘어날 것이다.
반대로 정상인을 암환자로 오진하는 경우를 줄이고 싶다면 임계값을 오른쪽으로 옮겨(올려) 파란 클래스가 임계값 왼쪽에 모두 들어가게하면 되지만 이 경우, 진짜 암에 걸린 환자를 암환자가 아니라고 판단하는 경우도 늘어나게 된다.

처음에 핵심을 이야기하며 저 곡선의 아래 면적이 클수록 성능이 좋다고 했는데 이를 다르게 이야기하면 두 클래스를 더 잘 예측하는 모델일수록 곡선은 그림의 좌상단으로 가까워져 사각형에 가깝게 되고 성능이 안좋은 모델일수록 직선에 가까워져
곡선 아래 면적이 삼각형에 가깝게 된다.

즉 ROC curve는 임계값을 어떻게 설정해야할지 알고 싶을 때 임계값에 대한 정답율과 오답율의 비율을 보는 곡선이라고 이해하면 될 것이다. 

오늘은 이진분류모델의 임계값을 결정할 때 도움을 줄 수 있는 ROC curve에 대해 알아봤다.
다음에도 유익한 주제를 들고 찾아뵐 수 있기를 기대하며 글을 마친다.
